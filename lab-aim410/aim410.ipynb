{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning with Keras on Amazon SageMaker\n",
    "\n",
    "Last update: December 3rd, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker is a modular, fully managed Machine Learning service that lets you easily build, train and deploy models at any scale.\n",
    "\n",
    "In this notebook, we'll use Keras (with the TensorFlow backend) to build a simple Convolutional Neural Network (CNN). We'll then train it to classify the Fashion-MNIST image data set. Fashion-MNIST is a Zalando dataset consisting of a training set of 60,000 examples and a validation set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes: it's a drop-in replacement for MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources\n",
    "  * Amazon SageMaker documentation [ https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html ]\n",
    "  * SageMaker SDK \n",
    "    * Code [ https://github.com/aws/sagemaker-python-sdk ] \n",
    "    * Documentation [ https://sagemaker.readthedocs.io/ ]\n",
    "  * Fashion-MNIST [ https://github.com/zalandoresearch/fashion-mnist ] \n",
    "  * Keras documentation [ https://keras.io/ ]\n",
    "  * Numpy documentation [ https://docs.scipy.org/doc/numpy/index.html ]\n",
    "  \n",
    "### https://gitlab.com/juliensimon/aim410\n",
    "### Twitter: @julsimon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the latest SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sagemaker in /opt/conda/lib/python3.7/site-packages (1.45.1)\n",
      "Requirement already up-to-date: smdebug-rulesconfig==0.1.2 in /opt/conda/lib/python3.7/site-packages (0.1.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.17.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied, skipping upgrade: requests<2.21,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (2.20.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.9.2)\n",
      "Requirement already satisfied, skipping upgrade: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.10.32)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<2.21,>=2.20.0->sagemaker) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<2.21,>=2.20.0->sagemaker) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<2.21,>=2.20.0->sagemaker) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<2.21,>=2.20.0->sagemaker) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.1->sagemaker) (42.0.2.post20191201)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.14.0,>=1.13.32 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->sagemaker) (1.13.32)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->sagemaker) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->sagemaker) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /opt/conda/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.32->boto3>=1.10.32->sagemaker) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.32->boto3>=1.10.32->sagemaker) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker smdebug-rulesconfig==0.1.2 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'describe_notebook_instance' to get the Role ARN of the instance datascience.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image(\"/root/C/src/aim410/fashion-mnist-sprite.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.17.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.3.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.25.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (42.0.2.post20191201)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to download the data set from the Internet. Fortunately, Keras provides a simple way to do this. The data set is already split (training and validation), with separate Numpy arrays for samples and labels. \n",
    "\n",
    "We create a local directory, and save the training and validation data sets separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_val, y_val) = fashion_mnist.load_data()\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok = True)\n",
    "\n",
    "np.savez('./data/training', image=x_train, label=y_train)\n",
    "np.savez('./data/validation', image=x_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53668\n",
      "-rw-r--r-- 1 root root 47100506 Dec  8 06:53 training.npz\n",
      "-rw-r--r-- 1 root root  7850506 Dec  8 06:53 validation.npz\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at our Keras code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m, \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m backend \u001b[34mas\u001b[39;49;00m K\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptimizers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SGD\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlosses\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m categorical_crossentropy\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcallbacks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Callback, EarlyStopping\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpreprocessing\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mimage\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ImageDataGenerator\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m multi_gpu_model, to_categorical\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Script mode doesn't support requirements.txt\u001b[39;49;00m\n",
      "\u001b[37m# Here's the workaround ;)\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minstall\u001b[39;49;00m(package):\n",
      "    subprocess.call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, package])\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \n",
      "    \u001b[37m# Keras-metrics brings additional metrics: precision, recall, f1\u001b[39;49;00m\n",
      "    install(\u001b[33m'\u001b[39;49;00m\u001b[33mkeras-metrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mkeras_metrics\u001b[39;49;00m\n",
      "    \n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m128\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dense-layer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m512\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dropout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.2\u001b[39;49;00m)\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--gpu-count\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    args, _ = parser.parse_known_args()\n",
      "    \n",
      "    epochs     = args.epochs\n",
      "    lr         = args.learning_rate\n",
      "    batch_size = args.batch_size\n",
      "    dense_layer = args.dense_layer\n",
      "    dropout    = args.dropout\n",
      "    \n",
      "    gpu_count  = args.gpu_count\n",
      "    model_dir  = args.model_dir\n",
      "    training_dir   = args.training\n",
      "    validation_dir = args.validation\n",
      "    \n",
      "    x_train = np.load(os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtraining.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    y_train = np.load(os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtraining.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    x_val  = np.load(os.path.join(validation_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    y_val  = np.load(os.path.join(validation_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    \n",
      "    \u001b[37m# input image dimensions\u001b[39;49;00m\n",
      "    img_rows, img_cols = \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m# Tensorflow needs image channels last, e.g. (batch size, width, height, channels)\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m K.image_data_format() == \u001b[33m'\u001b[39;49;00m\u001b[33mchannels_last\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        x_train = x_train.reshape(x_train.shape[\u001b[34m0\u001b[39;49;00m], img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "        x_val = x_val.reshape(x_val.shape[\u001b[34m0\u001b[39;49;00m], img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "        input_shape = (img_rows, img_cols, \u001b[34m1\u001b[39;49;00m)\n",
      "        batch_norm_axis=-\u001b[34m1\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[37m# Keras is configured with channels first (Apache MXNet backend)\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mChannels first, exiting\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "        exit(-\u001b[34m1\u001b[39;49;00m)\n",
      "        \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mx_train shape:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, x_train.shape)\n",
      "    \u001b[36mprint\u001b[39;49;00m(x_train.shape[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mtrain samples\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(x_val.shape[\u001b[34m0\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mtest samples\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m# Normalize pixel values\u001b[39;49;00m\n",
      "    x_train  = x_train.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    x_val    = x_val.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    x_train /= \u001b[34m255\u001b[39;49;00m\n",
      "    x_val   /= \u001b[34m255\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Convert class vectors to binary class matrices\u001b[39;49;00m\n",
      "    num_classes = \u001b[34m10\u001b[39;49;00m\n",
      "    y_train = to_categorical(y_train, num_classes)\n",
      "    y_val   = to_categorical(y_val, num_classes)\n",
      "    \n",
      "    model = Sequential()\n",
      "    \n",
      "    \u001b[37m# 1st convolution block\u001b[39;49;00m\n",
      "    model.add(Conv2D(\u001b[34m64\u001b[39;49;00m, kernel_size=(\u001b[34m3\u001b[39;49;00m,\u001b[34m3\u001b[39;49;00m), padding=\u001b[33m'\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, input_shape=input_shape))\n",
      "    model.add(BatchNormalization(axis=batch_norm_axis))\n",
      "    model.add(Activation(\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(MaxPooling2D(pool_size=(\u001b[34m2\u001b[39;49;00m,\u001b[34m2\u001b[39;49;00m), strides=\u001b[34m2\u001b[39;49;00m))\n",
      "    \n",
      "    \u001b[37m# 2nd convolution block\u001b[39;49;00m\n",
      "    model.add(Conv2D(\u001b[34m128\u001b[39;49;00m, kernel_size=(\u001b[34m3\u001b[39;49;00m,\u001b[34m3\u001b[39;49;00m), padding=\u001b[33m'\u001b[39;49;00m\u001b[33mvalid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(BatchNormalization(axis=batch_norm_axis))\n",
      "    model.add(Activation(\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(MaxPooling2D(pool_size=(\u001b[34m2\u001b[39;49;00m,\u001b[34m2\u001b[39;49;00m), strides=\u001b[34m2\u001b[39;49;00m))\n",
      "\n",
      "    \u001b[37m# Fully connected block\u001b[39;49;00m\n",
      "    model.add(Flatten())\n",
      "    model.add(Dense(dense_layer))\n",
      "    model.add(Activation(\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    model.add(Dropout(dropout))\n",
      "\n",
      "    \u001b[37m# Output layer\u001b[39;49;00m\n",
      "    model.add(Dense(num_classes, activation=\u001b[33m'\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(model.summary())\n",
      "\n",
      "    \u001b[34mif\u001b[39;49;00m gpu_count > \u001b[34m1\u001b[39;49;00m:\n",
      "        model = multi_gpu_model(model, gpus=gpu_count)\n",
      "                    \n",
      "    model.compile(loss=categorical_crossentropy,\n",
      "                  optimizer=SGD(lr=lr, decay=\u001b[34m1e-6\u001b[39;49;00m, momentum=\u001b[34m0.9\u001b[39;49;00m, nesterov=\u001b[34mTrue\u001b[39;49;00m),\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                  keras_metrics.precision(), \n",
      "                  keras_metrics.recall(),\n",
      "                  keras_metrics.f1_score()])\n",
      "    \n",
      "    \u001b[37m# Use image augmentation\u001b[39;49;00m\n",
      "    \u001b[37m# Not useful for this data set, but this is how to set it up\u001b[39;49;00m\n",
      "    \u001b[37m# datagen = ImageDataGenerator(\u001b[39;49;00m\n",
      "    \u001b[37m# rotation_range=20,\u001b[39;49;00m\n",
      "    \u001b[37m# width_shift_range=0.2,\u001b[39;49;00m\n",
      "    \u001b[37m# height_shift_range=0.2,\u001b[39;49;00m\n",
      "    \u001b[37m# horizontal_flip=True)\u001b[39;49;00m\n",
      "\n",
      "    \u001b[37m#datagen.fit(x_train)\u001b[39;49;00m\n",
      "    \u001b[37m#model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\u001b[39;49;00m\n",
      "    \u001b[37m#                validation_data=(x_val, y_val), \u001b[39;49;00m\n",
      "    \u001b[37m#                epochs=epochs,\u001b[39;49;00m\n",
      "    \u001b[37m#                steps_per_epoch=len(x_train) / batch_size,\u001b[39;49;00m\n",
      "    \u001b[37m#                verbose=1)\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Only needed because of the BatchNormalization layer\u001b[39;49;00m\n",
      "    sess = tf.Session()\n",
      "    sess.run(tf.local_variables_initializer())  \n",
      "    \n",
      "    model.fit(x_train, y_train, batch_size=batch_size,\n",
      "                    validation_data=(x_val, y_val), \n",
      "                    epochs=epochs)\n",
      "    \n",
      "    score = model.evaluate(x_val, y_val, verbose=\u001b[34m0\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mValidation loss    :\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m0\u001b[39;49;00m])\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mValidation accuracy:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m1\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# save Keras model in SavedModel format for Tensorflow Serving\u001b[39;49;00m\n",
      "    sess = K.get_session()\n",
      "    tf.saved_model.simple_save(\n",
      "        sess,\n",
      "        os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel/1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\n",
      "        inputs={\u001b[33m'\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.input},\n",
      "        outputs={t.name: t \u001b[34mfor\u001b[39;49;00m t \u001b[35min\u001b[39;49;00m model.outputs})\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize /root/C/src/aim410/mnist_keras_tf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main steps are:\n",
    "  * receive and parse command line arguments: five hyper parameters, and four environment variables (we'll get back to these in a moment)\n",
    "  * load the data sets\n",
    "  * make sure data sets have the right shape for TensorFlow (channels last)\n",
    "  * normalize data sets, i.e. tranform [0-255] pixel values to [0-1] values\n",
    "  * one-hot encode category labels (not familiar with this? More info: [ https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/ ])\n",
    "  * Build a Sequential model in Keras: two convolution block with max pooling, followed by a fully connected layer with dropout, and a final classification layer. Don't worry if this sounds like gibberish, it's not our focus today\n",
    "  * Train the model, leveraging multiple GPUs if they're available.\n",
    "  * Print statistics\n",
    "  * Save the model in TensorFlow serving format\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train outside of SageMaker (just like on your laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training on SageMaker, let's run this code locally and make sure that it trains fine. We just need to set the four environment variables that it expects, and run the script with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_NUM_GPUS=0\n",
      "env: SM_MODEL_DIR=/tmp/model\n",
      "env: SM_CHANNEL_TRAINING=data\n",
      "env: SM_CHANNEL_VALIDATION=data\n",
      "Using TensorFlow backend.\n",
      "Collecting keras-metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Keras>=2.1.5 in /opt/conda/lib/python3.7/site-packages (from keras-metrics) (2.3.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.17.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.13.0)\n",
      "Installing collected packages: keras-metrics\n",
      "Successfully installed keras-metrics-1.1.0\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "2019-12-08 06:53:23.261188: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-12-08 06:53:23.265699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz\n",
      "2019-12-08 06:53:23.265902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56144dd7d840 executing computations on platform Host. Devices:\n",
      "2019-12-08 06:53:23.265930: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,440,202\n",
      "Trainable params: 2,439,818\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> tp\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0> fn\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/C/src/aim410/mnist_keras_tf.py\", line 139, in <module>\n",
      "    sess = tf.Session()\n",
      "AttributeError: module 'tensorflow' has no attribute 'Session'\n"
     ]
    }
   ],
   "source": [
    "# Number of GPUs on this machine\n",
    "%env SM_NUM_GPUS=0\n",
    "# Where to save the model\n",
    "%env SM_MODEL_DIR=/tmp/model\n",
    "# Where the training data is\n",
    "%env SM_CHANNEL_TRAINING=data\n",
    "# Where the validation data is\n",
    "%env SM_CHANNEL_VALIDATION=data\n",
    "\n",
    "!/bin/rm -rf $SM_MODEL_DIR\n",
    "!python /root/C/src/aim410/mnist_keras_tf.py --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  aim410.ipynb  fashion-mnist-sprite.png  mnist_keras_tf.py\n"
     ]
    }
   ],
   "source": [
    "!ls /root/C/src/aim410/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are these environment variables important anyway? Well, they will be automatically passed to our script by SageMaker, so that we know where the data sets are, where to save the model, and how many GPUs we have. So, if you write your local code this way, **there won't be anything to change** to run it on SageMaker.\n",
    "\n",
    "This feature is called '**script mode**', it's the recommended way to work with built-in frameworks on SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the notebook instance (aka 'local mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code runs fine. Now, let's try to run it inside the built-in TensorFlow environment provided by SageMaker. For fast experimentation, let's use local mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow py2 container will be deprecated soon.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='mnist_keras_tf.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='local',\n",
    "                          framework_version='1.15', \n",
    "                          script_mode=True,\n",
    "                          hyperparameters={'epochs': 1}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the local location of the training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_training_input_path   = 'file://root/C/src/aim410/data/training.npz'\n",
    "local_validation_input_path = 'file://root/C/src/aim410/data/validation.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist_keras_tf.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-96aff985605d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlocal_training_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlocal_validation_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stage_user_code_in_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mcode_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_stage_user_code_in_s3\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mdependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m         )\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/fw_utils.py\u001b[0m in \u001b[0;36mtar_and_upload_dir\u001b[0;34m(session, bucket, s3_key_prefix, script, directory, dependencies, kms_key)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0msource_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_files_to_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         tar_file = sagemaker.utils.create_tar_file(\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0msource_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TAR_SOURCE_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         )\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/utils.py\u001b[0m in \u001b[0;36mcreate_tar_file\u001b[0;34m(source_files, target)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;31m# Add all files from the directory into the root of the directory structure of the tar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;31m# Create a TarInfo object from the file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettarinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mgettarinfo\u001b[0;34m(self, name, arcname, fileobj)\u001b[0m\n\u001b[1;32m   1805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstat\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdereference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mnist_keras_tf.py'"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit({'training': local_training_input_path, 'validation': local_validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, our job runs fine locally. Let's now run the same job on a managed instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data set to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker training instances expect data sets to be stored in Amazon S3, so let's upload them there. We could use boto3 to do this, but the SageMaker SDK includes a simple function: [Session.upload_data()](https://sagemaker.readthedocs.io/en/stable/session.html).\n",
    "\n",
    "\n",
    "\n",
    "*Note: for high-performance workloads, Amazon EFS and Amazon FSx for Lustre are now also supported. More info [here](https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'keras-fashion-mnist'\n",
    "\n",
    "# Upload the training data set to 'keras-fashion-mnist/training'\n",
    "training_input_path   = sess.upload_data('data/training.npz', key_prefix=prefix+'/training')\n",
    "\n",
    "# Upload the validation data set to 'keras-fashion-mnist/validation'\n",
    "validation_input_path = sess.upload_data('data/validation.npz', key_prefix=prefix+'/validation')\n",
    "\n",
    "print(training_input_path)\n",
    "print(validation_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done with our data set. Of course, in real life, much more work would be needed for data cleaning and preparation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Managed Spot Training, and enable debugging with Amazon SageMaker Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EC2 Spot Instances have long been a great cost optimization feature, and spot training is now available on SageMaker.\n",
    "This blog [post](https://aws.amazon.com/blogs/aws/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/) has more info.\n",
    "\n",
    "We're also using Amazon SageMaker Debugger to check for unwanted training conditions. **ZERO KERAS CODE NEEDED!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a managed training job for 'mnist_keras_tf.py', \n",
    "# using a single c5.2xlarge spot instance running TensorFlow 1.15 in script mode\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='mnist_keras_tf.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.p3.2xlarge',\n",
    "                          framework_version='1.15', \n",
    "                          script_mode=True,\n",
    "                          train_use_spot_instances=True,        # Use spot instance\n",
    "                          train_max_run=600,                    # Max training time\n",
    "                          train_max_wait=3600,                  # Max training time + spot waiting time\n",
    "                          rules = [Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "                                   Rule.sagemaker(rule_configs.overfit())]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the training and validation data sets stored in S3\n",
    "\n",
    "tf_estimator.fit({'training': training_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take about 10 minutes. Please take a look at the training log. The first few lines show SageMaker preparing the managed instance. While the job is training, you can also look at metrics in the AWS console for SageMaker, and at the training log in the the AWS console for CloudWatch Logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the status of the debug rules we configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = tf_estimator.latest_training_job.name\n",
    "client = tf_estimator.sagemaker_session.sagemaker_client\n",
    "\n",
    "description = client.describe_training_job(TrainingJobName=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "for status in description['DebugRuleEvaluationStatuses']:\n",
    "    status.pop('LastModifiedTime')\n",
    "    status.pop('RuleEvaluationJobArn')\n",
    "    pprint.pprint(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at tensor information saved in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_path = description[\"DebugHookConfig\"][\"S3OutputPath\"] + job_name + '/' + 'debug-output/'\n",
    "\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$s3_output_path\"\n",
    "\n",
    "aws s3 ls --recursive $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smdebug\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "trial = create_trial(s3_output_path)\n",
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = trial.tensor('loss').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to a real-time endpoint accelerated by Amazon Elastic Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is complete, the trained model is saved in S3, and is now ready to be deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Inference is a feature that lets you attach fractional GPU acceleration to any EC2 instance. It's also available on SageMaker.\n",
    "\n",
    "This blog [post](https://aws.amazon.com/blogs/aws/amazon-elastic-inference-gpu-powered-deep-learning-inference-acceleration/) has more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to an endpoint backed by a single c5.large instance,\n",
    "# accelerated by a medium-size elastic inference accelerator\n",
    "\n",
    "tf_endpoint_name = 'keras-tf-fmnist-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "#tf_predictor = tf_estimator.deploy(initial_instance_count=1,\n",
    "#                                   instance_type='ml.p2.xlarge', # $1.361/hour in eu-west-1\n",
    "#                                   endpoint_name=tf_endpoint_name)      \n",
    "\n",
    "tf_predictor = tf_estimator.deploy(initial_instance_count=1, # Performance comparable to p2.xlarge:\n",
    "                         instance_type='ml.c5.large',        # $0.134/hour in eu-west-1\n",
    "                         accelerator_type='ml.eia1.medium',  # + $0.140/hour in eu-west-1\n",
    "                         endpoint_name=tf_endpoint_name)     # = 80% discount :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic model tuning is a great feature that helps you find automatically the best hyper parameters for your training job.\n",
    "\n",
    "This blog [post](https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-automatic-model-tuning-now-supports-random-search-and-hyperparameter-scaling/) has more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter ranges :\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'epochs' :       IntegerParameter(5, 20),\n",
    "    'learning-rate': ContinuousParameter(0.001, 0.1, scaling_type='ReverseLogarithmic'), \n",
    "    'batch-size':    IntegerParameter(32, 1024),\n",
    "    'filters':       IntegerParameter(4, 64),\n",
    "    'dense-layer':   IntegerParameter(32, 1024),\n",
    "    'dropout':       ContinuousParameter(0.2, 0.8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define the metric we're optimizing for, in this case we want to maximize the validation accuracy. We also grab other metrics from the training log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'validation_accuracy'\n",
    "\n",
    "objective_type = 'Maximize'\n",
    "\n",
    "metric_definitions = [\n",
    "    {'Name': 'training_loss',        'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'training_accuracy',    'Regex': 'acc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation_loss',      'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation_accuracy',  'Regex': 'val_acc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'training_precision',   'Regex': 'precision: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'training_recall',      'Regex': 'recall: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'training_f1_score',    'Regex': 'f1_score: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation_precision', 'Regex': 'val_precision: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation_recall',    'Regex': 'val_recall: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation_f1_score',  'Regex': 'val_f1_score: ([0-9\\\\.]+)'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, it's time to put everything together, and configure the tuning job. Same estimator as above, without the debugging job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(entry_point='mnist_keras_tf.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.p3.2xlarge',\n",
    "                          framework_version='1.15', \n",
    "                          script_mode=True,\n",
    "                          train_use_spot_instances=True,        # Use spot instance\n",
    "                          train_max_run=600,                    # Max training time\n",
    "                          train_max_wait=3600                   # Max training time + spot waiting time\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# Configure a training job using the Tensorflow estimator, the parameter ranges and the metric defined above.\n",
    "# Let's run ten individual jobs, two by two.\n",
    "\n",
    "tuner = HyperparameterTuner(tf_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=20,\n",
    "                            max_parallel_jobs=2,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the tuning job, just like a normal estimator. We definitely want to use spot training here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the tuning job, passing the location of the data sets in S3.\n",
    "\n",
    "tuner.fit({'training': training_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, you can view it in the AWS console for SageMaker: individual jobs (and their logs), best training job so far, etc.\n",
    "\n",
    "Of course, you can also inspect the job programatically using [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html) : *decribe_hyper_parameter_training_job()*, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect jobs with Amazon SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model tuning automatically creates a new experiment, and pushes information for each job. \n",
    "\n",
    "**ZERO KERAS CODE NEEDED!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "exp = HyperparameterTuningJobAnalytics(\n",
    "    sagemaker_session=sess, \n",
    "    hyperparameter_tuning_job_name=tuner.latest_tuning_job.name\n",
    ")\n",
    "\n",
    "df = exp.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is the Swiss army knife for columnar data. Let's just look at the top job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job = df.sort_values('FinalObjectiveValue', ascending=0)[:1]\n",
    "best_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job_name = best_job['TrainingJobName'].to_string(index=False).strip()\n",
    "best_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job = sm.describe_training_job(TrainingJobName=best_job_name)\n",
    "\n",
    "best_model_artefact = best_job['ModelArtifacts']['S3ModelArtifacts']\n",
    "best_model_container = best_job['AlgorithmSpecification']['TrainingImage']\n",
    "\n",
    "print(best_job_name)\n",
    "print(best_model_artefact)\n",
    "print(best_model_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the best model, enabling data capture with Amazon SageMaker Model Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we want to save captured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_capture_path = 's3://jsimon-capture-data/'+best_model_name+'/'\n",
    "\n",
    "print(s3_capture_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we will capture 100% of model inputs and outputs. Of course, this is configurable.\n",
    "\n",
    "And you guessed it... **ZERO KERAS CODE NEEDED!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "cap = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    destination_s3_uri=s3_capture_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = best_job_name + '-ep'\n",
    "\n",
    "best_model_predictor = tuner.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge', \n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_samples = 10\n",
    "indices = random.sample(range(x_val.shape[0] - 1), num_samples)\n",
    "images = x_val[indices]/255\n",
    "labels = y_val[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "    \n",
    "prediction = best_model_predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_labels = prediction.argmax(axis=1)\n",
    "print('Predicted labels are: {}'.format(predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the validation dataset 250 samples at a time, storing labels and predicted labels as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_samples = 250\n",
    "all_labels=[]\n",
    "all_predicted_labels=[]\n",
    "\n",
    "import sys\n",
    "\n",
    "for i in range(0,x_val.shape[0] - 1,num_samples):\n",
    "    sys.stdout.write(str(i)+' ')\n",
    "    indices = range(i,i+num_samples)\n",
    "    images = x_val[indices]/255\n",
    "    labels = y_val[indices]\n",
    "    prediction = best_model_predictor.predict(images.reshape(num_samples, 28, 28, 1))['predictions']\n",
    "    prediction = np.array(prediction)\n",
    "    predicted_labels = prediction.argmax(axis=1)\n",
    "    all_labels.extend(labels)\n",
    "    all_predicted_labels.extend(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the confusion matrix, to compare predicted labels with real labels for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predicted_labels)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "fmt = 'd'\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] < thresh else \"black\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "classes = range(10) # Labels are sorted \n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we're capturing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$s3_capture_path\"\n",
    "\n",
    "aws s3 ls --recursive $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$s3_capture_path\"\n",
    "\n",
    "aws s3 cp --recursive $1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head tensorflow-training-191204-1329-020-c5780384-ep/AllTraffic/2019/12/04/15/24-07-182-4923659b-97ae-4e72-be22-953cb5b0e079.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete endpoint for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')\n",
    "#sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://gitlab.com/juliensimon/aim410\n",
    "### Twitter: @julsimon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
